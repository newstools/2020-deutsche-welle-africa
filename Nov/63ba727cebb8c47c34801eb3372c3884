No conference on artificial intelligence (AI), machine learning or robotics would be complete without its fair share of technologists, programmers and engineers. But scan the list of attendees at the 2020 Rise of AI Summit, a hybrid (digital and physical) event this week in Berlin (November 17-18, 2020) and the number of people from health insurance companies, banks and venture capitalists is astonishing. As one of the founders of the event, CEO of Asgard Capital, Fabian Westerheide, said in his opening remarks on "The Next Decade of AI, we are in a 'renaissance' of the technology." Westerheide says we're seeing a "refurbishment of ideas from the 1960s, 70s and 80s," combined with the amount of data we have now and today's processing power. He calls it "old ideas, new execution, and new capital." With extra stress on the capital. That change has happened in the last four years. Westerheide and other speakers at Rise of AI seemed positively angry about the sluggishness of European politics on AI After decades of development and numerous so-called "AI winters" of hibernation, AI fully arrived in 2016 when AlphaGo, an AI-driven system playing a Chinese game called Go, beat Lee Se-dol, the-then human, Go world champion. Attention has quickly turned to making money with the (re)emerging technology and ideology. "Between 2017 and 2019, AI became big business," says Westerheide. It is "unprecedented," says Westerheide, how much capital is now flowing into AI — "China: 130 billion, Germany: first 2 billion, then another 3 billion, European Union: 20 billion." Send  Facebook   Twitter   google+   Whatsapp   Tumblr   linkedin   stumble   Digg   reddit   Newsvine Permalink https://p.dw.com/p/3iK6h But there is a downside. Politics and regulation have taken the "sexy" out of AI. There's less innovation right now and a greater focus on "dry, robotic laws." It will be "painful," he says "as it usually is when public administrations give out money, but that also means [the cash] won't dry up. So, if you're in AI, stay in AI. This is huge." Westerheide, a self-declared "no fan of taxation," says the future of AI in Europe will be painful with political regulation Whether AI is truly mainstream remains a matter of interpretation, however. Its advocates, such as Westerheide, are certainly intent on its getting there. He does, after all, have a vested interest as the head of an investment firm, specialized in the field. But he and other speakers seemed positively angry at the slow progress so far. It's clear that if you want to make money with AI, you've got to get on the AI and robotics speakers' circuit. Rise of AI is only one of four German AI events in these final months of 2020. Concurrent to Rise of AI, you've got ML Munich (November 16-18), where ML = machine learning. Next week, you've got a TRUSTinAI conference in Kaiserslautern (November 26). And on December 10, there's the European AI Forum in Berlin. Take your pick. Topics, if not the speakers, will overlap from one to the other, most notably, mainstream issues like trust and ethics in AI. Opportunity and challenge: Getting a better mix of human and machine intelligence in AI But it's on the circuit that you're likely to make the connections you'll need to learn how to move AI systems into the real mainstream. There's a push to take AI from purely software-based, data-driven, decision-making machines in industry, like cliché "black boxes" behind the scenes, and "scale" them up to tangible applications that affect people's lives in the physical world. That could be applications involving the Internet of Things — appliances in your kitchen communicating with online retailers and manufacturers running diagnostics —  or in health care, agriculture, climate and resource management, down to apps on your phone that let you book a human to find your AI-powered autonomous car and wash it while you're out to lunch — or, indeed, at a virtual conference on AI. Beyond that, there's AI in the physical, military world. But that's a topic that even the European Commission's white paper "On Artificial Intelligence — A European approach to excellence and trust" — won't touch. Uszkoreit describes Europe's white paper on AI as "20 pages of rules and only four pages about actually doing things" Hans Uszkoreit, a professor and scientific director at the German Research Center for Artificial Intelligence (DFKI), says Germany and Europe lag behind the USA and China in AI-based internet services, consumer electronics, and the financial sector. It's unclear who's leading in public transport and the automotive sectors. But we're ahead in manufacturing, what Germany calls Industry 4.0, and enterprise AI — a means of combining human and machine intelligence. So, that would present both gaps in the market and ready-made opportunities for anyone wanting to make it big in AI. Without wanting to get too technical, AI is moving away from simple pattern recognition towards systems that can respond to real-world events and causes, mixing what's called "implicit" and "explicit" knowledge to arrive at specific solutions to specific problems, rather than standardized solutions. Uszkoreit says digitalization runs so deep in China, you can't imagine it, but people have embraced things like the Chinese coronavirus tracing app "One of the challenges of AI now is how to amplify human intelligence," said Uszkoreit in his session on the Global AI Landscape, "and, using language technology [Ed.: such as semantic search and natural language processing (NLP)] and visualization to bridge the [gap] between machines and decision-makers." So, if you're looking for a way to truly make money with AI, and you're willing to take Uszkoreit's word for it, you may want to look into developing some of the following: Systems that can interpret "unstructured data" for quality management, transform half-written documents into a machine-readable format, predict and detect events, anomalies, move from narrow to broad AI applications, hybrid AI and human-centered computing for education, health care and personal assistance. But all that's way too deep for the purposes of this article. Whatever you do, you may want to do it in the USA or China, the latter being a country that Westerheide says is "hungrier" than Europe. Uszkoreit, who has lived in China, says the Chinese even "like" their country's coronavirus tracing app —"they feel safer for it." Europe, meanwhile, will either tie you up knots, he says, or refuse to collect a lot of useful data on the grounds of "outdated" data protection and privacy ideals. Simple question, simple answer: Uszkoreit says Europe's biggest problems are arrogance, fear, and a risk-averse attitude to funding for early research and startups. Send  Facebook   Twitter   google+   Whatsapp   Tumblr   linkedin   stumble   Digg   reddit   Newsvine Permalink https://p.dw.com/p/3lEM4 Uszkoreit says we have a "Teutonic fear" of AI. It's either too good and will steal our jobs, or not good enough for critical tasks, or evil and will turn against us. We're obsessed with regulation and an "arrogance" that wants to teach the rest of the world what is ethical and trustworthy, he says. We should, says Uszkoreit, focus more on protecting people and saving lives, than protecting and saving their data. "I am extremely pessimistic," says Uszkoreit, "instead of building fantastic AI applications for our citizens, European AI is asked to start with rules, constraints and standards. We block most kinds of human-centered AI." Germany's Federal Government Commissioner for Digital Affairs, Dorothee Bär, followed Uszkoreit and Westerheide at Rise of AI, but seemed unable to veer from her carefully worded script. So, there was no direct response. Bär says Germany needs to attract more top talent in technology and engineering DW did, however, ask Bär whether Westerheide was right to say the future of AI in Europe would be highly regulated, "painful and less sexy" now that politics had caught on. "Yes," said Bär, "sometimes I feel the same way. But I really hope we can see the advantages and get away from the fear we have in Germany, which is more than in other countries." Bär says Germany is in a good position to innovate and build an AI society with humans controlling its use. But for that, Germany will need to attract more international talent, she says, "The catchword is technological sovereignty. If you look to the USA and China, you see the lights of passing speedboats. But we should work on our vision of AI made in Europe." Boos says "do or die." But be human. Or worse, lose out to China and the USA? As with most technological shifts in society, timing is everything. Chris Boos, CEO of a German AI company called Arago, says 80% of what we do today, apart from language and risky innovation, can be done by machines. That's a fact, he says. But whenever he convinces industry heads of that, their reaction is: "Okay, let's make a 20-year-plan." "And I just don't get it," said Boos. "A lot of people have been trying to slow this down, worrying about machines taking over, but that's not the problem. The problem is that this is happening very quickly and whoever makes it happen, will have a huge economic benefit, and if you don't make it happen, you are simply screwed." Over 100 AI experts have written to the UN asking them to ban lethal autonomous weapons — those that use AI to act independently. No so-called "killer robots" currently exist, but advances in artificial intelligence have made them a real possibility. Experts said these weapons could be "the third revolution in warfare," after gunpowder and nuclear arms. The "first revolution in warfare" was invented by the Chinese, who started using the black substance between the 10th and 12th centuries to propel projectiles in simple guns. It gradually spread to the Middle East and Europe in the following two centuries. Once perfected, firearms using gunpowder proved to be far more lethal than the traditional bow and arrow. The invention of gunpowder also introduced artillery pieces to the battlefield. Armies started using basic cannons in the 16th century to fire heavy metal balls at opposing infantrymen and breach defensive walls around cities and fortresses. Far more destructive field guns were invented in the 19th century and went on to wreak havoc in the battlefields of World War I. Guns that fire multiple rounds in rapid succession were invented in the late 19th century and immediately transformed the battlefield. Machine guns, as they came to be known, allowed soldiers to mow down the enemy from a protected position. The weapon's grisly effectiveness became all too clear in WWI as both sides used machine guns to wipe out soldiers charging across no man's land. Military thinkers did not ignore the invention of the first airplane in 1903. Six years later, the US military bought the first unarmed military aircraft, the 1909 Wright Military Flyer. Inventors experimented with more advanced fighter and bomber aircraft in the following years. Both became standard features in many of the national air forces established by the end of WWI. Armies had traditionally used soldiers and horses to fight and transport military equipment. But around WWI, they started using more machines such as tanks and armored vehicles. Faster and more destructive armies were the result. Nazi Germany put this new form of "mechanized warfare" to destructive effect in WWII using an attack strategy known as "Blitzkrieg" ("lightning war"). Although artillery was effective, it had a relatively limited range. The missile's invention in WWII suddenly allowed an army to strike a target hundreds of kilometers away. The first missile — the German V-2 — was relatively primitive, but it laid the foundation for the development of guided cruise missiles and intercontinental ballistic missiles (ICBM) capable of carrying nuclear warheads. Jet aircraft first saw action alongside traditional propeller airplanes at the end of WWII. Jet engines dramatically increased an aircraft's speed, allowing it to reach a target quicker and making it far harder for an adversary to shoot it down. After WWII, military reconnaissance planes were developed that could fly higher than 25 kilometers (15.5 miles) and faster than the speed of sound. The "second revolution in warfare" announced its horrific arrival on August 6, 1945 when the US dropped the first nuclear bomb — "Little Boy" — on the city of Hiroshima in Japan, killing between 60,000 and 80,000 people instantly. In the Cold War that followed, the US and Soviet Union developed thousands of even more destructive warheads and raised the specter of a devastating nuclear war. Recent decades have witnessed the ever more prevalent use of computers to conduct war. The devices made military communication quicker and easier and radically improved the precision and efficiency of many weapons. Armed forces have recently focused on developing cyber warfare capabilities to defend national infrastructure and attack foreign adversaries in cyberspace. Author: Alexander Pearson