Facebook on Wednesday said it had removed around 800 QAnon groups for posts that celebrate violence, show intent to use weapons, or try to attract followers with patterns of violent behavior. The social media giant also imposed restrictions on 1,950 more public and private QAnon accounts that it could find. They will no longer be recommended to users and will be harder to find in Facebook searches as well. QAnon is an umbrella term for groups of internet conspiracy theorists that began before the US presidential elections of 2016, claiming that key Democrats were running a pedophile ring out of a restaurant basement in Washington DC. Read more: Spread of coronavirus fake news causes hundreds of deaths President Donald Trump told reporters that he did not know much about the QAnon groups, but said that they held a favorable view of him. "I don't know much about the movement, other than I understand they like me very much," he said. The movement centers on anonymous postings from someone using the nickname Q, who claims to be a high-ranking official in the Trump administration. The followers idolize President Trump. While the movement began in obscure corners of the internet, it has entered mainstream politics recently. Many belonging to the group believe that top Democrats and Hollywood elite eat children. There are also some theories floating around that many of them have been executed in military tribunals, and have been replaced by actors. According to some QAnon tales, Trump was elected to save the country from satanic cannibals. "Is that supposed to be a bad thing? We are saving the world, from a radical left philosophy," said Trump, when asked about it. Read more: Twitter takes down accounts linked to QAnon conspiracy theory The FBI has identified QAnon as a potential domestic terror threat, and that some of its followers have been charged with murder and kidnapping. Facebook said that some of these followers would keep forming new groups with code words, and therefore, tracking them down would be an ongoing task. Facebook has been under increasing pressure to curb the spread of fake news and conspiracy theories, especially in the months leading to the 2020 presidential elections. The social network said that hundreds of thousands of its users belong to one or more QAnon group, but declined to give more information. Read more: How denial and conspiracy theories fuel coronavirus crisis in Pakistan It also removed 980 groups that supported rioting. The majority of them belonged to right-wing militia, but some also belonged to the leftist Antifa movement. Previously, Twitter has also removed thousands of QAnon accounts from its network. Google has also removed multiple QAnon-related videos from YouTube for violating its guidelines. However, they do not put an umbrella ban on the QAnon movement. tg/rc (AP, Reuters)